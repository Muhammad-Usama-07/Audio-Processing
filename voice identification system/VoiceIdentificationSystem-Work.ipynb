{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary Libraries"
      ],
      "metadata": {
        "id": "UL1mshDb4DOo"
      },
      "id": "UL1mshDb4DOo"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b928af34",
      "metadata": {
        "id": "b928af34"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wave\n",
        "import time\n",
        "import pickle\n",
        "import pyaudio\n",
        "import warnings\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from scipy.io.wavfile import read\n",
        "import python_speech_features as mfcc\n",
        "from sklearn.mixture import GaussianMixture\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice feature extracting methods\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rgWw6rvO4bOa"
      },
      "id": "rgWw6rvO4bOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466ca8d1",
      "metadata": {
        "id": "466ca8d1"
      },
      "outputs": [],
      "source": [
        "def calculate_delta(array):\n",
        "    rows,cols = array.shape\n",
        "    deltas = np.zeros((rows,20))\n",
        "    N = 2\n",
        "    for i in range(rows):\n",
        "        index = []\n",
        "        j = 1\n",
        "        while j <= N:\n",
        "            if i-j < 0:\n",
        "                first =0\n",
        "            else:\n",
        "                first = i-j\n",
        "            if i+j > rows-1:\n",
        "                second = rows-1\n",
        "            else:\n",
        "                second = i+j\n",
        "            index.append((second,first))\n",
        "            j+=1\n",
        "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
        "    return deltas\n",
        "def extract_features(audio,rate):\n",
        "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)\n",
        "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
        "    delta = calculate_delta(mfcc_feature)\n",
        "    combined = np.hstack((mfcc_feature,delta))\n",
        "    return combined"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recording method"
      ],
      "metadata": {
        "id": "hgRaYMeV8MXw"
      },
      "id": "hgRaYMeV8MXw"
    },
    {
      "cell_type": "code",
      "source": [
        "def record_audio_train():\n",
        "    Name =(input(\"Please Enter Your Name:\"))\n",
        "    os.mkdir(f\"training_set/{Name}\")\n",
        "\n",
        "    for count in range(5):\n",
        "        FORMAT = pyaudio.paInt16\n",
        "        CHANNELS = 1\n",
        "        RATE = 44100\n",
        "        CHUNK = 512\n",
        "        RECORD_SECONDS = 10\n",
        "        device_index = 2\n",
        "        audio = pyaudio.PyAudio()\n",
        "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
        "                        rate=RATE, input=True,frames_per_buffer=CHUNK)\n",
        "        print (\"recording started\")\n",
        "        Recordframes = []\n",
        "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "            data = stream.read(CHUNK)\n",
        "            Recordframes.append(data)\n",
        "        print (\"recording stopped\")\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        audio.terminate()\n",
        "        OUTPUT_FILENAME=Name+str(count)+\".wav\"\n",
        "        WAVE_OUTPUT_FILENAME=os.path.join(\"training_set\",Name,OUTPUT_FILENAME)\n",
        "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
        "        waveFile.setnchannels(CHANNELS)\n",
        "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
        "        waveFile.setframerate(RATE)\n",
        "        waveFile.writeframes(b''.join(Recordframes))\n",
        "        waveFile.close()\n",
        "    return Name"
      ],
      "metadata": {
        "id": "5oaPfIFr8P8J"
      },
      "id": "5oaPfIFr8P8J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Method"
      ],
      "metadata": {
        "id": "QiFU-Jlm8eOO"
      },
      "id": "QiFU-Jlm8eOO"
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model():\n",
        "    FORMAT = pyaudio.paInt16\n",
        "    CHANNELS = 1\n",
        "    RATE = 44100\n",
        "    CHUNK = 512\n",
        "    RECORD_SECONDS = 10\n",
        "    device_index = 2\n",
        "    audio = pyaudio.PyAudio()\n",
        "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
        "                    rate=RATE, input=True,frames_per_buffer=CHUNK)\n",
        "    print (\"recording started\")\n",
        "    Recordframes = []\n",
        "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "        data = stream.read(CHUNK)\n",
        "        Recordframes.append(data)\n",
        "    print (\"recording stopped\")\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    audio.terminate()\n",
        "    OUTPUT_FILENAME=\"sample.wav\"\n",
        "    WAVE_OUTPUT_FILENAME=os.path.join(\"testing_set\",OUTPUT_FILENAME)\n",
        "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
        "    waveFile.setnchannels(CHANNELS)\n",
        "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
        "    waveFile.setframerate(RATE)\n",
        "    waveFile.writeframes(b''.join(Recordframes))\n",
        "    waveFile.close()\n",
        "    \n",
        "    \n",
        "    source   = \"./testing_set/sample.wav\"\n",
        "    modelpath = \"./trained_models/\"\n",
        "    # Read Audio Files\n",
        "    gmm_files = [os.path.join(modelpath,fname) for fname in os.listdir(modelpath) if fname.endswith('.gmm')]\n",
        "    #Load the Gaussian gender Models\n",
        "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
        "\n",
        "    speakers   = [i.split('.gmm')[0] for i in os.listdir(modelpath)]\n",
        "\n",
        "\n",
        "    sr,audio = read(source)\n",
        "    vector   = extract_features(audio,sr)\n",
        "    log_likelihood = np.zeros(len(models))\n",
        "    for i in range(len(models)):\n",
        "        gmm    = models[i]  #checking with each model one by one\n",
        "        scores = np.array(gmm.score(vector))\n",
        "        log_likelihood[i] = scores.sum()\n",
        "\n",
        "    winner = np.argmax(log_likelihood)\n",
        "    print(winner)\n",
        "    print(\"\\tdetected as - \", speakers[winner])"
      ],
      "metadata": {
        "id": "C7NXL1OT80yV"
      },
      "id": "C7NXL1OT80yV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "VoiceIdentificationSystem-Work.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}