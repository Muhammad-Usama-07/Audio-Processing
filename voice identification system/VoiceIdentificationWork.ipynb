{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2024217",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "    1. Record and Train methods\n",
    "    \n",
    "        i. This method records the user's voice five times by calling record_audio() method\n",
    "        ii. Calling noise of the collected voice data by callig clean_audio() method\n",
    "        iii. Training sklearn model \"GaussianMixture\" on voice data by callig train_model() method \n",
    "        \n",
    "    2. Test model by calling test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea383547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.Record audio for training \n",
      " 2.Test Model \n",
      " 3.Exit \n",
      "2\n",
      "recording started\n",
      "recording stopped\n",
      "10\n",
      "\tdetected as -  test\n",
      "\n",
      " 1.Record audio for training \n",
      " 2.Test Model \n",
      " 3.Exit \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import pyaudio\n",
    "import warnings\n",
    "import glob\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import noisereduce as nr \n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Feature and label array\n",
    "\n",
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first =0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j\n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "def extract_features(audio,rate):\n",
    "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)\n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature,delta))\n",
    "    return combined\n",
    "def record_audio():\n",
    "    Name =(input(\"Please Enter Your Name:\"))\n",
    "    os.mkdir(f\"training_set/{Name}\")\n",
    "\n",
    "    for count in range(5):\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        CHUNK = 512\n",
    "        RECORD_SECONDS = 10\n",
    "        device_index = 2\n",
    "        audio = pyaudio.PyAudio()\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,frames_per_buffer=CHUNK)\n",
    "        print (\"recording started\")\n",
    "        Recordframes = []\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            Recordframes.append(data)\n",
    "        print (\"recording stopped\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        OUTPUT_FILENAME=Name+str(count)+\".wav\"\n",
    "        WAVE_OUTPUT_FILENAME=os.path.join(\"training_set\",Name,OUTPUT_FILENAME)\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(Recordframes))\n",
    "        waveFile.close()\n",
    "    clean_audio(Name)\n",
    "    train_model(Name)\n",
    "    \n",
    "\n",
    "def clean_noise(Name):\n",
    "    for name in glob.glob('./training_set/'+Name+'/*.wav'):\n",
    "        rate, data = wavfile.read(name)\n",
    "        reduced_noise = nr.reduce_noise(y=data, sr=rate,prop_decrease = 0.8)\n",
    "        filename = name.split('\\\\')[1]\n",
    "        wavfile.write('./training_set/'+Name+'/'+filename, rate, reduced_noise)\n",
    "    \n",
    "\n",
    "\n",
    "def train_model(name):\n",
    "    source   = f\"./training_set/{name}/\"   \n",
    "    dest = \"trained_models\\\\\"\n",
    "    file_paths = glob.glob(f\"training_set/{name}/*.wav\")\n",
    "#     train_file = \"training_set_addition.txt\"\n",
    "#     file_paths = open(train_file,'r')\n",
    "    count = 1\n",
    "\n",
    "    features = np.asarray(())\n",
    "    for _ in file_paths:\n",
    "        path = _.split(\"\\\\\")[1]\n",
    "#         print(a)\n",
    "#     for path in file_paths:\n",
    "#         path = path.strip()\n",
    "        sr,audio = read(source + path)\n",
    "        vector   = extract_features(audio,sr)\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "        if count == 5:\n",
    "            gmm = GaussianMixture(n_components = 6, max_iter = 200, covariance_type='diag',n_init = 3)\n",
    "            gmm.fit(features)\n",
    "            # dumping the trained gaussian model\n",
    "            picklefile = path.split(\".\")[0]\n",
    "            picklefile = picklefile[:-1]\n",
    "            picklefile = picklefile +\".gmm\"\n",
    "            pickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "            print('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)\n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1\n",
    "def test_model():\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "    CHUNK = 512\n",
    "    RECORD_SECONDS = 10\n",
    "    device_index = 2\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,frames_per_buffer=CHUNK)\n",
    "    print (\"recording started\")\n",
    "    Recordframes = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        Recordframes.append(data)\n",
    "    print (\"recording stopped\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    OUTPUT_FILENAME=\"sample.wav\"\n",
    "    WAVE_OUTPUT_FILENAME=os.path.join(\"testing_set\",OUTPUT_FILENAME)\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(Recordframes))\n",
    "    waveFile.close()\n",
    "    \n",
    "    for name in glob.glob('./testing_set/*.wav'):\n",
    "        rate, data = wavfile.read(name)\n",
    "        reduced_noise = nr.reduce_noise(y=data, sr=rate)\n",
    "        wavfile.write('./testing_set/sample.wav', rate, reduced_noise)\n",
    "    \n",
    "    source   = \"./testing_set/sample.wav\"\n",
    "    modelpath = \"./trained_models/\"\n",
    "    # Read Audio Files\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "    #Load the Gaussian gender Models\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\n",
    "    speakers   = [i.split('.gmm')[0] for i in os.listdir(modelpath)]\n",
    "\n",
    "\n",
    "    sr,audio = read(source)\n",
    "    vector   = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models))\n",
    "    for i in range(len(models)):\n",
    "        gmm    = models[i]  #checking with each model one by one\n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    print(winner)\n",
    "    print(\"\\tdetected as - \", speakers[winner])\n",
    "    \n",
    "    \n",
    "\n",
    "while True:\n",
    "    choice=int(input(\"\\n 1.Record audio for training \\n 2.Test Model \\n 3.Exit \\n\"))\n",
    "    if(choice==1):\n",
    "        record_audio()\n",
    "    elif(choice==2):\n",
    "        test_model()\n",
    "    if(choice>=3):\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a6c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
