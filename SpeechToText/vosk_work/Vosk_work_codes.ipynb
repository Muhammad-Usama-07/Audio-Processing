{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Usama-07/Audio-Processing/blob/main/SpeechToText/vosk_work/Vosk_work_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe audio by uploading and use web socket server transcripton"
      ],
      "metadata": {
        "id": "JN5nmoMA4zp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# front-end code"
      ],
      "metadata": {
        "id": "VhEqUeRb5Fko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>Speech Recognition Client</title>\n",
        "</head>\n",
        "<body>\n",
        "  <input type=\"file\" id=\"audioFileInput\" accept=\"audio/*\">\n",
        "  <button id=\"recognizeButton\">Recognize</button>\n",
        "\n",
        "  <script>\n",
        "    const socket = new WebSocket('ws://localhost:2700');\n",
        "    let audioBuffer;\n",
        "\n",
        "    socket.addEventListener('open', () => {\n",
        "      console.log('Connected to the server');\n",
        "    });\n",
        "\n",
        "    socket.addEventListener('message', (event) => {\n",
        "      const response = event.data;\n",
        "      console.log('Recognition result:', response);\n",
        "    });\n",
        "\n",
        "    const recognizeAudio = async () => {\n",
        "      if (!audioBuffer) {\n",
        "        console.error('No audio file selected');\n",
        "        return;\n",
        "      }\n",
        "\n",
        "      const audioData = new Blob([audioBuffer], { type: 'audio/wav' });\n",
        "      socket.send(audioData);\n",
        "    };\n",
        "\n",
        "    document.getElementById('audioFileInput').addEventListener('change', (event) => {\n",
        "      const file = event.target.files[0];\n",
        "      const reader = new FileReader();\n",
        "\n",
        "      reader.onload = (event) => {\n",
        "        audioBuffer = event.target.result;\n",
        "        console.log('Audio file loaded');\n",
        "      };\n",
        "\n",
        "      reader.onerror = (event) => {\n",
        "        console.error('Error occurred while reading the audio file');\n",
        "      };\n",
        "\n",
        "      reader.readAsArrayBuffer(file);\n",
        "    });\n",
        "\n",
        "    document.getElementById('recognizeButton').addEventListener('click', recognizeAudio);\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "ZV-0_Yza3p4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}